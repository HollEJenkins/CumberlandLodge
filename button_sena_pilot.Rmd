---
title: 'Pilot study: Cumberland Lodge course'
author: "Kate Button and Emily Sena"
date: "`r Sys.Date()`"
output:
  word_document: default
  html_document: default
bibliography: button_sena_bibliography.bib
csl: apa.csl
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Evaluating the primary outcome measure developed to assess methodological rigour of experimental studies spanning biomedicine

*N.B. Draft version only! Written by Dorothy based on Kate/Emily protocol for full trial.*

## Background and rationale 
Publication bias is the term for what occurs whenever the research findings in the published literature differ systematically from of the population of all studies completed in a given area [@rothstein2006publication]. Publication bias is wasteful, hindering science’s incremental progress [@ioannidis2012science]. Publication bias arises from the decisions of investigators, reviewers, and editors to submit or accept manuscripts for publication based on certain study characteristics. 

An early study by Mahoney [-@mahoney1977publication] demonstrated how positive results biased reviewers to favour a paper, regardless of study quality. Mahoney randomly assigned referees to review one of 5 versions of a manuscript, all with identical introduction and methods sections, but different results and discussion sections (positive, negative, methods only, mixed results with positive discussion, mixed results with negative discussion). The methods, data presentation, scientific contribution, and publication merit of manuscripts with positive results were rated as being nearly twice as high as manuscripts with negative results. Interestingly, the scientific contribution and publication merit ratings for the manuscripts where reviews were based solely on the introduction and methods, were comparable to those for the positive results. Thus, negative findings seemed to disproportionally and detrimentally affect appraisals of study quality and merit.  
  
This study suggested that one way to prevent publication bias in the review and editorial process is to base the decision to publish solely on assessing the scientific merit of the study rationale, and methods without access to the results. During ‘results-free’ review, authors submit other-wise complete manuscripts, but omit any discussion of results, and provisional accepted is based on peer-review of the introduction and methods alone. The results and discussion of accepted manuscripts are then reviewed in second stage, to check for adherence to methods and to allow minor revisions.  
  
However, attempts to evaluate the effectiveness of results-free peer review could be confounded by a form of self-selection bias; authors who are invested in the principles of scientific rigour and transparency are more likely to submit their work to special issues piloting results-free review. Similarly, such initiatives may attract reviewers that are more switched on to the research integrity and publication bias debate.  

To overcome these limitations, the we plan to conduct a randomised controlled trial (RCT), comparing reviewer recommendations based on results-free review versus review-as-usual for papers submitted to BMC Series and other Nature-Springer journals recruited into the study. 

To increase sensitivity of the trial, we will include a measure of methodological quality of the studies under consideration, using a tool developed for this purpose, enabled on an online platform. 
  
## Objectives  

To objective of the pilot study is to evaluate the online tool for assessing study quality. From the pilot we will gather quantitative information, in terms of inter-rater agreement of two independent raters, and also qualitative information, in terms of raters' comments on ease of use and intelligibility. We anticipate that some aspects of the online tool may be modified in light of the findings.  

## Methods

### Raters
Raters will be 30 early-career researchers from the fields of psychology and biomedical sciences who are attending a course on Advanced Methods in Reproducible Science in January 2019.

### Papers to be rated  

xx papers will be selected to represent the kind of articles that will be included in the RCT, i.e. papers describing in vivo or in vitro experimental research using humans or non-human animals. We will not include observational epidemiology studies, secondary analyses of existing datasets, systematic reviews or meta-analysis of existing publications.  
  
### Procedure 
 
Each rater will be introduced to the online tool and then asked to rate a pool of 6 papers. Each paper will be assigned to two independent raters. For each rated item, agreement between raters will evaluated using ?kappa ($\kappa$). Sources of disagreement will be discussed between the two raters and one of the course tutors, so that a set of qualitative comments can be collated to consider whether there are any systematic reasons for disagreement. 

  
## Results  
Table 1 shows the proportion of agreement between two raters for each rated feature. 

(Table 1 to go here)

## References

<!-- Here's the original list of reference, but we're using a bibtex file now - MLS

Coursol A and Wagner EE. (1986) Effect of positive findings on submission and acceptance: A note of meta-analysis bias. Professional Psychology: Research and Parctice 17: 136-137. 
Dickersin K. (1990) The existence of publication bias and risk factors for its occurrence. JAMA 263: 1385-1389.  
Fanelli D. (2010) "Positive" results increase down the Hierarchy of the Sciences. PLoS One 5: e10068.  
Fanelli D. (2012) Negative results are disappearing from most disciplines and countries. Scientometrics: 891–904.  
Findley MG, Jensen NM, Malesky EJ, et al. (2016) Can results-free review reduce publication bias? The results and implications of a pilot study Comparative Political Studies: 1-37.  
Franco A, Malhotra N and Simonovits G. (2014) Publication bias in the social sciences: Unlocking the file drawer. Science 345: 1502-1505.  
Greenwald AG. (1975) Consequences of prejudice against the null hyptohesis Psychol Bull 82: 1-20. 
Ioannidis JP. (1998) Effect of the statistical significance of results on the time to completion and publication of randomized efficacy trials. JAMA 279: 281-286.  
Ioannidis JPA. (2012) Why Science Is Not Necessarily Self-Correcting. Perspectives on Psychological Science 7: 645-654.  
Mahoney MJ. (1977) Publication prejudices: An experimental study of confirmatory bias in the peer review system Cognit Ther Res 1: 161-175.  
Rothstein H, Sutton AJ and Borenstein M. (2005) Publication bias in meta-analysis : prevention, assessment and adjustments, Chichester: John Wiley.
Shadish WR, Jr., Doherty M and Montgomery LM. (1989) How many studies are in the file drawer? An estimate from the family/marital psychotherapy literature Clin Psychol Rev 9: 589-603.  
Smart RG. (1964) The importance of negative results in psychological research. The Canadian Psychologist 5: 225-232.  
Smith ML. (1980) Sex bias in counseling and psychotherapy Psychol Bull 87: 392-407. 
Sterling TD. (1959) Publication Decisions and Their Possible Effects on Inferences Drawn from Tests of Significance--Or Vice Versa. Journal of the American Statistical Association 54: 30-34.  
-->
