---
title: "Simulation_ex1_intro_rmd"
author: "DVM Bishop"
date: "08/01/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Simulation introduction by DVM Bishop
 19th March 2017; updated 24th March 2018, rmd version 8th Jan 2019

The R script Simulation_ex1_intro.R works fine and has many comments that explain what it does. This version is in R Markdown just to show the difference between .R and .Rmd. In the context of teaching about simulation to novices, an advantage of Rmd is that it makes it much easier to run chunks of code. This first chunk of code doesn't do anything except display a message - it's just there to demonstrate how to run a chunk of code (press little green arrow at top right of code chunk)

```{r Initialexplanation, include=TRUE}
# The hashtag at the start of this line indicates it is a comment
# Commented lines explain the script. They do not do anything when you run a script
# It is good practice to include lots of comments in your code so that you and others
# can make sense of it when returning to it after a delay

print('Initialexplanation chunk has been run')
```
## Preliminaries

It is also good practice to explicitly set your working directory, at start of script. This is the default location for finding/saving files. You can see what your current working directory is with command getwd() and you can set the working directory with setwd(*location*).

Here is the command I can use to set working directory to Dropbox/BBSCR_STARS/Bishop on my mac

 **setwd('/Users/dorothybishop/Dropbox/BBSRC_STARS/Bishop')**

If you are working on a PC, the syntax is a bit different, e.g.

 **setwd<-"C:\\Users\\dorothybishop\\Dropbox\\BBSRC_STARS\\Bishop**
 
You will need to set the directory to be specific for your machine

You can easily set your working directory by going to menu item 
Session|Set Working Directory - this allows you to select Source File Location, which sets the working directory to same place as where you have saved this script. Do that now and then run the next chunk.

```{r checkdirectory}
getwd() #get the working directory
```

The next step is to specify any packages that are needed later in the program.
R has hundreds of packages that contain useful functions
You can use the **library()** or **require()** commands to tell R which ones you need, 
as below, but! these will only work if the packages are already installed on your machine.

When you try to use functions from a package you don't have, you'll get an error message.
If that happens, you can download the package by going to Tools|Install Packages and selecting the one you need. You only need to install the package once.

I'll assume you have installed the MASS, Hmisc and yarr functions, and we'll now make sure they are included in our script.  (We are not using the first two in this exercise, but will need them later). We'll also take this opportunity to disable scientific notation, which can make output hard to interpret in some situations. See http://stackoverflow.com/questions/25946047/how-to-prevent-scientific-notation-in-r.

Now run the next chunk.

```{r preliminaries, include=FALSE}
library(MASS) # for mvrnorm function to make multivariate normal distributed vars
library(Hmisc) # for rcorr function: gives correlation matrix and p values
library(yarrr) # for pirate plots (see below)

options(scipen=999) 


```
You'll see a lot of red writing, which looks alarming, but is (hopefully) just documenting what happens as packages load.  
  
*There is a way to turn off these messages. I can't remember what it is, but it should be esay to find on Google. If you work it out, feel free to modify this script and then push to Git, so I can approve the change.  If you do that, please delete this sentence but add an explanation of the change.*

## Now let's simulate!

R has a nifty function called rnorm which just creates 'random normal deviates', i.e. random numbers that are normally distributed.

You just have to say how many numbers you want (N), and what the mean and SD of the distribution is. I want to simulate z-scores, so I will pick a mean of zero and SD of one.

Naming conventions vary: I tend to preface my variables with 'my' to avoid confusion with any pre-existing R functions.

So in the chunk below I just specify the number (myN), mean (myM) and SD (mySD)

```{r make.sample1}
myN <- 20 #You could type myN = 20 to get the same result, but R purists prefer <- to assign a value
myM1 <- 0
mySD <- 1 #I've picked mean 0 and SD 1 so I can simulate z-scores

myvectorA<-rnorm(n = myN, mean = myM1, sd = mySD) #Simulate data with specified mean, standard deviation, and sample size
# rnorm generates a random sample from a normal distribution
# for any function, you can use help for more information, e.g. help(rnorm)

# Now let's look at the numbers we've generated
myvectorA #View myvectorA on the console
mean(myvectorA) # View the mean of myvectorA
sd(myvectorA) # View the sd of myvectorA
```
## Questions

The odds are that the mean and sd of your vector are not exactly 0 and 1.

Why is this?

Is there any way you could modify this part of the script to generate a set of numbers where the mean and SD are closer to 0 and 1 respectively?

Now try the next chunk.

```{r makesample2}
# ------------------------------------------------------------------------
# Create another sample with same N and SD but different mean
# ------------------------------------------------------------------------
myM2 <- 0.5 # The mean for the population this sample comes from
#We don't need to specify myN or mySD - these values are just carried over from the previous chunk.
myvectorB<-rnorm(n = myN, mean = myM2, sd = mySD) 
myvectorB
mean(myvectorB)
sd(myvectorB)
```

N.B. Unless you use a command called set.seed, you'll get different values for myM1 and myM2 every time you run the script.
For explanation of set.seed see http://rfunction.com/archives/62 

Next we will compare our two vectors with a t-test. Note that R defaults to the Welch t-test which does not assume equal variances between groups, and can give fractional degrees of freedom.

```{r do.ttest}
# ------------------------------------------------------------------------
# compare our two vectors with a t.test
# ------------------------------------------------------------------------
t.test(myvectorA,myvectorB) #see http://www.statmethods.net/stats/ttest.html
```

# Reformat data

This next bit is not required for the t-test, but is useful for showing one way of reformatting data into a data frame, which is a format that we need if we want to use a nice visual display called a pirate plot. A data frame is a kind of matrix for holding data that can take both numeric and non-numeric values. 

N.B. Usually when simulating data, you would generate a whole set with one command in a dataframe. The method above is used just to make each step more transparent.

We're  going to stack vectorA and vectorB in a single column in a data frame with another column to designate the group

```{r make.df}
# First we'll make a dummy data frame to hold the data
mydf <- data.frame(matrix(data=NA,nrow=myN*2,ncol=2)) #NA indicates missing data
colnames(mydf)<-c('Group','Score') #c is concatenate function, puts what follows in a sequence
# colnames gives the columns' names, which can be used later on to refer to them in formulae
range1<-1:myN #range of rows for group 1 data
range2<-(myN+1):(2*myN) #range of rows for group 1 data
range1
range2
# to see the vectors for range1 and range2
```

An easy way to inspect mydf is to click on the term *mydf* in the Environment tab. If you look at mydf at this point, you'll see 40 rows and 2 columns, with NA values in each.

Next we need to populate the data frame with values, so we defined two ranges of rows, one for group1 and one for group2. Note that we do this using a formula based on the sample size - we *could* have 'hard coded' range1 <- 1:20 and range2 <- 21:40, but this would be a *really* bad idea. See https://www.reddit.com/r/ProgrammerHumor/comments/6doae8/never_hard_code/.



```{r populate.df}
 mydf$Group[range1]<-1 # First set of rows allocated to group 1

# Square brackets used to refer to sections of a data frame
# Here we specify the column first with $Group, and then the range of rows.
# Same effect could be achieved with mydf[range1,1], indicating rows 1:myN, and column 1
 
 mydf$Group[range2]<-2 # Next block of rows allocated to group 2
 mydf$Score[range1] <- myvectorA # First block in Score column is vectorA
 mydf$Score[range2]<-myvectorB # 2nd block in Score column is vectorB
 
 #Now inspect mydf: you have data in the kind of table familiar from Excel or SPSS

```

Before going further, we'll just see a different way of doing the t-test, using the column names from the dataframe. This should give exactly the same result as the do.ttest chunk. This illustrates that there's usually many different ways of doing something in R. The method below is preferred as it is more flexible. It also illustrates the use of the tilde, ~, which is widely used in R statistics. 

X ~ Y means treat X as the dependent variable and Y as independent variable.  
  
With a data frame, many commands allow you to just identify relevant data from the column name, provided you specify the dataset in a data command. (I would not recommend using another approach where you 'Attach' a dataframe, though you may see this mentioned. It allows you to refer to columns without specifying the name of the data frame. In my experience, it just causes trouble.)


```{r do.ttest2}
t.test(Score ~ Group, data = mydf)


#A more ponderous way of doing the same thing, which may sometimes be necessary for some commands, is to refer to the variables by their full names, i.e. 
t.test(mydf$Score ~ mydf$Group)


```


## Saving results of statistical analysis as a variable

When we plot the result, we want to include a label showing the result of the t-test, so each time we run the t.test we will save this. We can do this by using the <- assignment symbol, as below. Instead of printing the t-test result to screen, it is now saved as myt. Note that myt is not a single number: it contains all the t-test output.

```{r save.t}

 myt <- t.test(Score ~ Group, data = mydf) 
 # Same t-test as before, but this time instead of displaying the result, we
#  save it as myt. 
```

To inspect myt, just type myt at the console. 
You will see it is a complex structure. Suppose we just want the t-value?
We can see individual bits of myt if we just type myt$ at the console: this will cause a list of components of myt to pop up. We can just select the one we want to see its value.
For the t-value, we just type  
  
myt$statistic  
  
and for the p-value,  
  
myt$p.value.

# Making a pirateplot

The pirateplot is a neat way of showing all the data. See help(pirateplot) or just Google 'pirateplot' for more information.
You can substitute 'boxplot' for a more conventional plot.
Either type of plot is far superior to usual bar graph. If you make a plot by running a R Markdown chunk, it will appear below the chunk, rather than in the Plots pane.

```{r makepirate}
 #------------------------------------------------------------------------------- 

 # If you don't clear it, each plot will be retained and can be viewed in the Plots window
 # But you may run out of memory eventually if you store too may plots
 
 # Turn the t-test result into a header for the graph;
 myheader=paste0('t = ', format(myt$statistic,digits=2),
                 '; p = ',format(myt$p.value,digits=3))
 # paste0 is used to bolt together text and/or numbers into a string
 # format is used to select number of decimal places to avoid v long string of numbers
 myheader #just used to display myheader on the console so you can check it
 
pirateplot(Score~Group,data=mydf,main=myheader,   xlab="Group", ylab="Score")
#
```

# Explore the simulation

Try re-running the script several times. If N is small, you will see what Geoff Cumming has called 'the dance of the p-values'. Even though you don't change the N or mean or SD of the population, the values dance around from run to run. See: https://www.youtube.com/watch?v=5OL1RqHrZQ8

Once you have experienced the p-values dancing, save the script under a new name.
You can then play around with the new version without worrying about losing the original.
Now try varying myN and/or myM1 or myM2 and re-running the script.

Explore to give insights into these questions:

What happens when myN is very large?

How often do you get a significant p-value when myvectorA and myvectorB have the same mean?

Once you feel you understand this script, you can look at: Simulation_ex1_multioutput.R
This is a pared-down version of this script which automatically runs 10 times for each of 2 sample sizes


  